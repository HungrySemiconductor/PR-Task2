# 模式识别实验报告

**姓　　名**：范红乐  
**班　　级**：计算机学院20250718班  
**学　　号**：2025E8007382043

## 1 实验概述

### 1.1 实验内容

​		实现两个通用的三层前向神经网络反向传播算法程序，一个采用批量方式更新权重，另一个采用单样本方式更新权重。分析不同隐含节点数对性能的影响不同学习率对收敛速度和稳定性的影响；比较批量更新与单样本更新的性能差异。网络结构固定的情况下，绘制出目标函数随着迭代步数增加的变化曲线

### 1.2 实验数据

<img src="E:\Typora\Typora\coding-study\image-20251229204817913.png" alt="image-20251229204817913" style="zoom: 67%;" />

## 2 算法实现

### 2.1 实验参数

```
├── data_loader.py		  	
├── network.py			# 三层神经网络结构
├── main.py				# 不同条件下的对比实验
├── comparison.py		# 单样本与批量更新的性能对比
└── imgs/				# 实验结果图
```

| 要求           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| 网络结构       | 三层神经网络（输入-隐含-输出）                               |
| 隐含层激活函数 | 双曲正切： $f(x) = tanh(x) = \dfrac{e^x-e^{-x}}{e^x + e^{-x}}$ |
| 输出层激活函数 | Sigmoid： $f(x) = \dfrac{1}{1+e^{-x}}$                       |
| 损失函数       | 平方误差：$E = \dfrac{1}{2}\sum_{j}(t_j-z_j)^2$              |
| 更新方式       | 单样本更新 single；批量更新 batch                            |
| 数据预处理     | 将3类数据做归一化处理，并分别设置类别标签为 [1, 0, 0]、[0, 1, 0]、[0, 0, 1]<br />训练集与测试集比例默认为 7:3 |

### 2.2 前向传播

- 隐含层输入：$net_h = \sum_iw_{ih}x_i$  	

- 隐含层输出：$y_h = tanh(net_h)$

- 输出层输入：$net_j = \sum_hw_{hj}y_h$

- 输出层输出：$z_j = sigmoid(net_j)$

- 计算误差： $E = \dfrac{1}{2}\sum_{j}(t_j-z_j)^2$

### 2.3 反向传播

- 输出层误差信号：$δ_j = \dfrac{-\partial E}{\partial net^k_j} = f'(net^k_j)(t^k_j-z^k_j)$  其中 $f'(net^k_j) = sigmoid'(net_j^k)$
- 隐含层误差信号：$δ_h = \dfrac{-\partial E}{\partial net^k_h} = f'(net^k_h)\sum_{j}w_{hj}\delta^k_j$  其中  $f'(net^k_h) = tanh'(net^k_h)$
- 输出层权重更新：$w_{hj} ← w_{hj} + η⋅δ_j ⋅ y_h$
- 隐含层权重更新：$w_{ih} ← w_{ih} + η⋅δ_h ⋅ x_i$
- 两种权重更新方式：
  - 单样本更新：随机梯度下降，每输入一个样本就立即更新权重
  - 批量更新：积累所有样本的梯度，每轮结束后统一更新权重

## 3 结果分析

图1 不同隐含层节点数的性能对比

1. 隐含层不同节点数目对训练精度的影响
   
   > 固定学习率，设置不同的隐含节点数，比较不同节点数对性能影响
   
   - 隐含层节点太少时，能够提取以及保存的模式较少，获得的模式不足以概括样本的所有邮箱信息，得不到样本的特定规律，导致识别同样模式的新样本的能力较差，学习能力较差
   - 隐含层节点多，学习时间变长，神经网络的学习能力较强，能学习较多输入数据之间的隐含模式。
   - 隐含层节点过多，学习能力过强，可能把训练输入样本与输出数据无关的非规律性模式学习进来，大都是一些样本噪声，导致过拟合，降低了模型泛化能力。（表现是在训练数据集上误差极小，测试数据集上误差较大）
   - 隐含层节点个数取决于样本中蕴含规律的个数以及复杂程度
     - 可以将隐含层个数设置为超参数，使用验证及验证，选择在验证集中误差最小的作为神经网络的隐含层的节点个数
     - 或者或通过简单的经验设置公式来确定隐含层神经元个数 $l=\sqrt{m+n}+α$（m输入层节点个数，n输出层节点个数，α一般是1-10的常数）

图2 不同学习率对比的示意图

2. 不同梯度更新步长对训练的影响

   > 固定隐含节点数，设置不同的学习率，比较不同学习率对性能影响



 3. 相同学习率与隐含节点数条件下，单样本更新与批量更新性能对比

    > 学习率设置为0.1，隐含节点数设置为10





在模式识别和神经网络实验中，“绘图看性能”通常指的是绘制**损失函数（Loss Function）**随迭代次数（Epochs）变化的曲线图。

这张图就像是模型的“学习心电图”，通过它你可以直观地看到模型是在“努力进步”还是“停滞不前”。

------

### 1. 损失函数曲线能看出什么？

损失函数（在你的代码里是 MSE 均方误差）衡量的是模型预测值与真实标签之间的**差距**。

- **收敛速度（Convergence Speed）：**
  - 曲线下降得有多快？如果曲线在前几个 Epoch 迅速掉头向下，说明学习率设置得比较合适，模型很快找到了正确的方向。
- **训练稳定性（Stability）：**
  - 曲线是平滑的还是剧烈震荡的？
  - **单样本更新（Single/Stochastic）：** 通常曲线会比较“抖”，因为它每看一个样本就改一次参数，容易受到个别噪声样本的影响。
  - **批量更新（Batch）：** 曲线通常非常平滑，因为它看完全部数据才更新一次，代表了整体趋势。
- **是否已经“学到头”了：**
  - 如果曲线变成了水平线（不再下降），说明模型已经收敛，再练下去也不会有明显进步了。

------

### 2. 通过对比图看“超参数”的影响

在你的实验报告要求中，通过绘图可以对比出三个核心性能点：

| **比较维度**                                                 | **观察损失曲线的特征**                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **隐含层节点数**                                             | 节点数太少，损失可能降不下去（欠拟合）；节点数太多，损失降得极快但验证集损失可能会反弹（过拟合）。 |
| **学习率 (![img](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAbCAYAAACqenW9AAABIklEQVR4AeySuUoDURSGB5dOUBRsFBsRUUGw0MJaQbDTSp/B57DRwofwEQQLrVxAJa1b4dZpEbukSULyfYEzXLIUqZPh/+Ys89+ZM3dmKOvhGJjTzeqr3RjjzScg1TDFNHgti93Yo3EPr3AJk3AEX1CAIlxoHic5hH04gx24BRfME+fgAHY1r5P8wwfMgLrhdAwVUM2oeZTqHJxrjfgLJ1CF0IKJZmf0TrM0luEZ/iA0QrIJZc3EplztnI9UJQhNkfjE79S8RVPdeUrwJr7kU5iddxWD874TU21QOMpDmN34RZpd5+VaIcw+xgVXNDvOS/8nzH4Ezac0U+Xz0iyGuWYBRkKuFTLnvSbWw0zeJk3bdMvwBvmPZN6Kf+ASzRf4hKwBAAD//ywrXwkAAAAGSURBVAMAkvEz/FVNgKEAAAAASUVORK5CYII=))** | 学习率太大，曲线会剧烈跳动甚至往上升（发散）；学习率太小，曲线下降极其缓慢，像在爬行。 |
| **更新方式**                                                 | 比较单样本和批量更新在达到相同损失值时，谁需要的迭代次数更少，谁的曲线更稳。 |

------

### 3. 调试时的“救命稻草”

如果你在调试时发现图长成下面这样，你就能立刻定位问题：

1. **曲线是一条水平高线：** 检查反向传播代码，可能是梯度计算错了，或者权重初始化得太小（比如全是 0），导致模型根本没在学。
2. **曲线直接冲向天际（越来越大）：** 学习率设置得太离谱了，赶紧调小 10 倍试试。
3. **训练集损失极低，但验证集损失很高：** 这就是典型的“死记硬背”（过拟合），你需要减少隐含层节点或者增加数据。

### 总结

**“绘图”不是为了好看，是为了验证你的数学公式和参数设置是否符合逻辑。**

你想让我帮你把绘制这种对比图的具体代码（`plot_results.py`）写出来吗？这样你运行完实验就能直接生成实验报告里需要的图表了。